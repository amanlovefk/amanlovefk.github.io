<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>结局是注定的</title><url>/post/20221228_01/</url><categories/><tags/><content type="html">反正要死的，何必着急呢。</content></entry><entry><title>Understanding Paxos</title><url>/post/understanding_paxos/</url><categories/><tags/><content type="html"> https://people.cs.rutgers.edu/~pxk/417/notes/paxos.html
The Consensus Problem Suppose you have a collection of computers and want them all to agree on something. This is what consensus about; consensus means agreement.
Consensus comes up frequently in distributed system design. There are various reasons why we want it: to agree on who gets access to a resource (mutual exclusion), agree on who is in charge (elections), or to agree on a common ordering of events among of a collection of computers (e.g. what action to take next, or state machine replication).
Replication may be the most common use of consensus. We set up collections (clusters) of servers, all of which will have replicated content. This provides fault tolerance: if any server dies, others are still running. It also provides scale: clients can read data from any available server although writing data will generally require the use of all servers and not scale at well. For many applications, though, reads far outnumber writes. To keep the content replicated, we have two design choices. We can funnel all write requests through one coordinator, which will ensure in-order delivery to all replicas or we can send updates any system but that system will coordinate thoses update with its replicas to ensure that all updates are applied in the same order on each replica. In the first case, we need consensus to elect that coordinator. In the second case, we need to run a consensus algorithm for each update to ensure that everyone agrees on the order.
The consensus problem can be stated in a basic, generic manner: One or more systems may propose some value. How do we get a collection of computers to agree on exactly one of those proposed values ?
The formal properties for asynchronous consensus are:
Validity: only the proposed values can be decided. If a process decides on some value, v, then some process must have proposed v. Uniform Agreement: no two correct processes (those that do not crash) can decide on different values Integrity: each process can decide a value at most once. Termination: all processes will eventually decide on a result Paxos Paxos is an algorithm that is used to achieve consensus among a distributed set of computers that communicate via an asynchronous network. One or more clients propose a value to Paxos and we have consensus when a majority of systems running Paxos agrees on of the proposed values. Paxos is widely used and is legendary in computer science it is the first consensus algorithm that has been rigorously proved to be correct.
Paxos simply selects a single value from one or more values that are proposed to it and lets everyone know what that value is. A run of the Paxos protocol results in the selection of single proposed value. If you need to use Paxos to create a replicated log (for a replicated state machine, for example), then you need to run Paxos repeatedly. This is called multi-Paxos.
Paxos provides abortable consensus. This means that some processes abort the consensus if there is contention while others decide on the value. Those processes that decide have to agree on the same value. Aborting allows a process to terminate rather than be blocked indefinitely. When a client proposes a value to Paxos, it is possible that the proposed value might fail if there was a completing concurrent proposal that won. The client will then have to propose the value again to another run of the Paxos algorithm.
Our assumptions for the algorithm are:
Concurrent proposals: One or more systems may propose a value concurrently. If only one system would propose a value then it is clear what the consensus would be. With multiple systems, we need to select one from among those values. Validity: The chosen value that is agreed upon must be one of the proposed values. The servers cannot just choose a random number. Majority rule: Once a majority of Paxos servers agrees on one of the proposed values, we have consensus on that value . This also implies that a majority of servers need to be functioning for the algorithm to run. To survive m failures, we need 2m + 1 systems. Asynchronous network:The network is unreliable and asynchronous : messages may get lost or arbitrarily delayed. The network may also get partitioned. Fail-stop faults: System may exhibit fail-stop faults. They may restart but need to remember there previous state to make sure they do not change their mind. Failures are not Byzantine. Unicasts: Communication is point-to-point. There is no mechanism to multicast a message atomically to the set of Paxos servers. Announcement: Once consensus is reached, the results can be make known to everyone. What we need in a distributed consensus protocol We have an environment of multiple systems (nodes), connected by a network, where one or more of these nodes may concurrently propose a value (e.g., perform an operation on a server, select a coordinator, add to a log, whatever&amp;hellip;). We need a protocol to choose exactly one value in cases where multiple competing values may be proposed.
We will call the processes that are proposing values proposers. We will also have processes called acceptors that will accept these values and help figure out which one value will be chosen.
Multiple proposers, single acceptor The simplest attempt to design a consensus protocol will use a single acceptor. We can elect one of our systesm to take on this role. Multiple proposers will concurrently propose various to a single acceptor. The acceptor chooses one of those proposed values. Unfortunately, this does not handle the case where the acceptor crashes. If it crashes after choosing a value, we will not know what value has been chosen and will have to wait for the acceptor to restart. We want to design a system that will be functional if the majority of nodes are running.
Fault tolerance: multiple acceptors To achieve fault tolerance, we will use a collection of acceptors. Each proposal will be sent to at least a mojority of these acceptors. If a quorum, or majority, of these acceptors chooses a particular proposed value (proposal) then that value will be considered chosen. Even if some acceptors crash, others are up so we will know the outcome. If an acceptor crashes after it accepted a proposal, other acceptors know that a value was chosen.
If an acceptor simply accepts the first proposed value it receives and cannot change its mind, it is possible that we may have no majority of accepted value. Depending on the order in which messages arrive at various acceptors, each acceptor may choose a different value or small groups of acceptors choose different values such that there is no majority of acceptors that choose the same proposed values. This tells us that acceptors may need to change their mind about which accepted value to choose. We want a value to be chosen only when a majority of acceptors accept the value.
Since we know that an acceptor may need to change its mind, we might consider just having an acceptor accept any value given by any proposer. A majority of acceptor may accept a value, which means that value is chosen. However, anothoer server may also tell a majority of acceptors to accept another value. Some acceptors will receive both of these proposals because to have a mojority means that both sets of proposals have at least one acceptor in common. That means at least one acceptor had to change its mind about what value is ultimately chosen, violating the integrity property. Once we choose a value, there is no going back.
To fix this, instead of just having a proposer propose a value, we will first ask it to contact a majority of acceptors and check whether a value has already chosen. If it has, then the proposer must propose that chosen value to the other acceptors. To implement this, we will need a two-phase protocol; check first and then provide a value.
Asking a proposer to check is not sufficient. Another proposer may come along after the checking phase and propose a different value. What if that second value is accepted by a majority and then the acceptors receive requests from the first proposer to accept its value? We again end up with two chosen values. The protocol needs to be modified to ensure that once we accept a value, we will abort competing proposals. To do this, Paxos will impose an ordering on proposals. Newer proposals will take precedence over old ones. If that first proposer tries to finish its protocol, its request will fail.
How Paxos works The case of characters Paxos has three entities:
Proposers: Receive requests (values) from clients and try to convince acceptors to accept there proposed values. Acceptors: Accept certain proposed values from proposers and let proposers know if something else was accepted. A response from an acceptor represents a vote for a particular proposal. Learners: Announce the outcome In practice, a single node may run proposer, acceptor, and learner roles. It is common for Paxos to coexist with the service that requires consensus (e.g., distributed storage) on a set of replicated servers, which each server taking on all three roles rather than using separate servers dedicated to Paxos. For the sake of discussing the protocol, however, we consider these to be independent entities.
What Paxos does A client sends a request to any Paxos proposer. The proposer then runs a two-phase protocol with the acceptors. Paxos is a majority-wins proptocol. A majority avoids split-brain problems and ensures that if you made a proposal and asked over 50% of the systems if somebody else made a proposal and they all reply non then you know for certain that no other system could have asked over 50% of the systems received the same answer. Because of this Paxos requires a majority of its servers to be running for the algorithm to terminate. A majority ensures that there is at least one node in common from one majority to another if servers die and restart. The system requires 2m+1 servers to tolerate the failure of m servers. As we shall see, Paxos requires a majority of acceptors. We can have one or a smaller number of proposers and learners.
Paxos acceptors cannot forget what they accepted, so they need to keep track of the information they received from proposers by writing it to stable storage. This is storage such as flash memory or disk, whose contents can be retrieved even if the process or system is restarted.
The Paxos protocol (initial version) Paxos is a two-phase protocol, meaning that the proposers interact with the acceptor twice. At a high level:
Phase 1: A proposer asks all the working acceptors whether anyone already received a proposal. If the answer is no, propose a value.
Phase 2: If a majority of acceptors agree on to this value then that is our consensus.
Right now, we will examine the mostly failure-free case. Later, we will augment the algorithm to correct for other failures.
When a proposer receives a client request to reach consensus on a value, the proposer must create a proposal number. This number must have two properties:
It must be unique. No two proposers can come up with the same number. It must be bigger than any previously used identifier used in the cluster. A proposer may use an incrementing counter or use a nanosecond-level timestamp to achieve this. If the number is not bigger than one previously used, the proposer will find out by having its proposal rejected and will have to try again. Prepare 请求的作用：
查找到可能已经选中的值。
帮助未完成的proposal继续完成提案
避免造成分裂的情况，比如 {S1, S2}, {S3}, {S4, S5}，先和 acceptor 打好招呼，不要接收比我编号更小的。比我更大的可以，因为当前 proposer 可以会挂掉，在它重启后可以选择一个更大的编号来中断之前未完成的提案过程；或者，其他的proposer替我继续这未完的旅程。
Failure examples Acceptor fails in phase 1 Suppose an acceptor fails during phase 1. That means it will not return a PROMISE message. As long as the proposer still gets response from a majority of acceptors, the protocol can continue to make progress.
Acceptor fails in phase 2 Suppose an acceptor fails during phase 2. That means it will not be able to send back an ACCEPTED message. This is also not a problem as long as enough of the acceptors are still alive and will respond so that the proposer or learner receives responses from a majority of acceptors.
Proposer fails in the Prepare phase If the proposer fails before it sent any messages, then it is the same as it did not run at all.
What if the proposer fails after sending one or more PREPARE msgs? An acceptor would have sent PROMISE responses back but no ACCEPT messages would follow, so there would be no consensus. Some other node will eventually run its version of Paxos and run as a proposer, picking its own ID. If the higher ID number works, then the algorithm runs. Otherwise, the proposer would have its request rejected and have to pick a higher ID number.
What if the proposer fails during the ACCEPT phase? At least one ACCEPT message was sent. Some another node proposes a new message with PREPARE(higher-ID). The acceptor responds by telling that proposer that an earlier proposal was already accepted. PROMISE(higher-ID, &amp;lt;old_ID, Value&amp;gt;)
If a proposer gets any PROMISE responses with a value then it must choose the response with the highest accepted ID and change its own value. It sends out: ACCEPT(higher-ID, Value)
If proposer fails in the ACCEPT phase, any proposer that takes over finishes the job of propagating the old value that was accepted.</content></entry><entry><title>Basic Paxos Deduction From single Proposer's Perspective</title><url>/post/eight/</url><categories/><tags/><content type="html">Paxos 算法的精髓在于其推导的过程。
Paxos 算法中本质上只需要两种角色：proposer 和 acceptor。故事就发生在这两个角色之间。
在正式开始推导之前，需要明确的一点是：何种情况下谁认为达成了共识？明确“谁”的主体意味着我们需要切换视角，从 proposer 的角度，还是从 acceptor 的角度，或是从上帝的视角？答案是我们要从 proposer 的角度来明确当前系统是否已经达成了共识。
“何种情况呢？” proposer 向所有 acceptor 发出一轮请求，如果返回的响应中的大多数的值是相同的，那么 proposer 就认为系统已经达成了共识；并把 该值返回给客户端。Paxos 算法强调的似乎是写，如果去读呢？也需要进行标准的 Paxos 算法过程，最后获得的那个值就是读取到的值。
每个 proposer 之间是平等的，独立的，proposer 之间并不会发生通信。在 Multi Paxos 算法中，为了提高共识算法的效率，会进行选主，这时候 proposer 之间会发生通信。现在我们讨论的是 Basic Paxos，proposer 之间不知道彼此的存在。
我们接下来的推导过程都要戴着单个 proposer 的帽子，看看这个微小的个体是如何参与到这个令人眼花缭乱的协议和过程中去的。
单个 Acceptor 故事在最开始的那个梦中，漫天星光只因我而闪烁 &amp;hellip;
让我们回到故事的起点，那时候我们还没有那么贪婪。只有一个 acceptor，有多个 proposer。这唯一的 acceptor 对于 proposer 提出的值如何决策呢？
等等，proposer 发出的消息格式是什么样子呢？虽然，我们站在第一级台阶上，也要搞清楚一些基本问题。这时候，协议还很简单：
proposer 向唯一的 acceptor 发出了消息，消息中唯一包含的就是提议的值，除此之外没有任何其他东西。
acceptor 收到之后如何反应呢？
Paxos 算法的活性要求我们必须要能够达成对一个值的共识，如今这个重任就放到唯一的 acceptor 身上。acceptor 可以采取两种行动：一是接受（accept), 二是拒绝（reject）。如果接受，接受哪个呢？毕竟 acceptor 对值没有偏好，proposer 之间也是众生平等，不能因为碰巧遇到了某个值就接受了它。换句话 说，对于 acceptor 来说，值本身不能给它提供决策需要的信息。acceptor 只能从其他维度来定义自己的接收规则。
我们需要一个规则，但是又不确定这个规则是什么？路有千万条，该走哪一条，哪一条又是活路呢？此时，我们无妨（不得不）假设我们的算法已经成型，现在要 用它来进行经常测试。先从最简单的场景开始。
如果只有一个 proposer，它只发出了一个提案，也就说整个系统中只有一个提案，那么最终的共识自然是这个提案了。收到提案的 proposer 该如何反应呢？ 拒绝吗？拒绝之后也没有其他提案了，无法达成共识。这个 proposer 只能接收这个唯一的提案。我们的接收规则可能非常复杂，但在当下这种一个proposer， 一个提案和一个acceptor的情况下它必须蕴含能达成的情况。我们观察一下，对于 acceptor 来说，这个唯一的提案有什么特征。前面提到了，acceptor 不会从值本身来决定接收还是拒绝，那么在这里，这个孤单的提案的特征是什么呢？是的，就是“一个”这个特征。一个意味着是第一个也是最后一个。目前，我们 的消息格式十分简陋，只有一个值，到 acceptor 这里的话，由于多个消息的存在，给消息附加了时间信息。
如果 acceptor 按照接收的顺序来决定接收规则呢？ 或者说 acceptor 接收它收到的每个提案。后面这种想法明显不靠谱，如果acceptor如何来者不拒， 系统的共识将会无法收敛。我们还是考虑从顺序上来定义接受规则。在只有一个提案的情况下，acceptor 可以将规则定义为：
a: 接收第一个收到的提案 b: 接收最后一个收到的提案 a 还是 b 呢？如果选 b, “最后一个”是一个相对的概念，意味着接下来没有收到任何消息。而在基于消息的共享模型中，一个消息可能会花费任意长的时间达到， 确定最后一个必须要有一个时间的限制，比如3分钟内。而 Paxos 算法中是没有这样的时间限制的，因此我们只能将规则定义为：
P1 一个Acceptor必须接受它收到的第一个提案 P1听起来有点过于简单，就这？？？别看人家轻描淡写的一句话，在现在这个场景（只有一个 proposer 只发出了一个 提案 给唯一的 acceptor）下是够用的。 当然，我们能隐约感受到它是一个局部的真理。就好像，火鸡养殖场里面，有一只练习时长不满一年的火鸡科学家，它观察到每天下午，它的住处都会出现事物， 于是它推测每天下午都会出现食物，这是一个真理。殊不知，在11月第四个星期三，下午没有出现食物，反而出现一位从未见过的巨人把它抓起来了。因为明天就是 感恩节，它被用来“感恩”了。
人类的记忆容纳不了太多没有逻辑的内容，因为这意味着我们不是踩着台阶上去了，而是从某种无法预测难以理解的地方突然达到了彼岸。我必须介绍一下我们继续 推导的思路，这对急需理解的读者们是一个救赎，不过，首先是自我的救赎。
我们首先假设大厦已经建成，然后有这个幻想去满足一些基本的场景，得到一个基本的简单的局部的规则。这个就是我们思维的起点。之后，我们进行如下的循环：
A: 通过反例发现已有规则的漏洞 B: 提出更加完善的规则 如果幸运的话，我们会在若干个循环后停在B。but, who knows ? 鉴于现在是 2022 年，是 Paxos 算法发表的30多年后，所以我们都心知肚明这是一次 装模作样的推导，我们会成功的，只要是很自然地被我们大脑所接受。
目前我们的 B 是 P1, 接下我们要对他进行挑刺。
多个 Acceptor 一个 acceptor 为啥不行？很简单，如果它挂掉了，proposer 将一直苦等，从它的角度来看，无法达成共识，这就违反了算法的活性要求。一个不行就多个吧。 毕竟，在分布式系统中我们的印象是，多个，有好多个， 服务器不止一个，而是一个集群，给我们提供“高可用”的服务。挂掉一个，不影响服务可用性。
既然是多个 acceptor，我们系统的可用性得到了保证，但是对于共识来说事情变得复杂起来。在只有一个 acceptor 的情况下，proposer 在回复中得到 确认后就认为自己的提案变成了共识。现在有多个acceptor，这些交互的过程又是怎样呢？
如果 proposer 只给一个 acceptor 发送请求，如果幸运的话，这个熟悉的战友挂掉的话，proposer 只能一直等下去了。所以，不仅决策端要配备多个 acceptor，proposer 也要灵活起来，不能把所有的鸡蛋都放在同一个篮子里，它决定给多个 proposer 都发送请求。那么，proposer 到底应该给多少个 acceptor 发送请求才能保证不会出现没人会它的情况呢？
等等，我们的系统不会要求出现所有的 acceptor 都挂掉还能正常进行共识协议工程吗？这可能吗？所以我们在讨论proposer该给多少个 acceptor 发送 消息之前，我们需要对于 acceptor 的集群故障做一个限制：在何种故障程度下共识算法要能够容忍错误并正常工作。
这种故障是指什么呢？Paxos 算法针对的是非拜占庭式的故障模型。对于 acceptor 来说，它可能会运行缓慢，宕机或者重启，但是不可能会破坏或者修改 或者欺骗 proposer，也就说，这里的故障没有“魔法”的存在。何种故障程度值得是集群中有几个可以正常工作（活的的，能产生响应的）。
Paxos 算法的工作的前提是 acceptor 中的多数可用，假设有 5 个 acceptor 节点，之中3个及以上的节点可用就能保证算法正常运行。
我们再回到proposer应该给多少个acceptor发送消息的问题上来。按照人类民主议会制的少数服从多数的选举制度的朴素思想，proposer 至少收到多数 的 acceptor的接受响应后，才可以认为自己的提案已经成为系统的共识。所以最简单的方法是给所有的acceptor都发送消息。
如果共有5个acceptor，其中3个接受了提案，但是中途挂掉了一个，所以只有两个接收的响应。这种情况下，proposer 就不能认为自己的提案被选中。这是一 个反例，也是我们后面要解决的问题。
现在我们需要明确从 proposer 的角度来说，怎样算达成了共识。proposer 在收到的消息中发现有多数接受了自己，就认为共识达成。这是 proposer 端的 决策规则。那么 acceptor 端又该如何定义接受规则呢？
我们先沿用 P1 这个接受规则。P1 实际限制了只能接收第一个收到的提案，意味如果可以接收第二个，那么共识就无法变得难以收敛（当然这是我们的一个直觉， 没有严谨的证明，目前为止，我们还在一系列的猜想当中，完全可以自由行路）。在多个 proposer 同时提案的过程中，acceptor 按照接收的值被划分成多个 不相交的集合。比如在记为 S1 ~ S5 的 acceptor 集群中根据收到的值 v1, v2, v3形成了互补相交的三个集合： {S1, S2}, {S3}, {S4, S5}。 这样就无法形成多数了。
假设为了 v1 让成为多数，proposer1 向 S3 又发出了请求，然后 S3 接受了它。这样我们就无法使用 P1 这个简单的接收规则了。需要修改 acceptor 的 接受规则，怎么改呢？首先排除掉接收每一个收到的提案。接收相同值的提案怎么样？但是在上面的情形中，还是无法形成共识。假如 proposer1, proposer2, proposer 3 都坚持己见，不肯妥协，那么算法是无法达到安全性的。proposer必须要作出让步，毕竟算法的目的是达成共识，进而保证多副本的状态一致，而 不是从单个 proposer 的利益考虑。如果一个 proposer 能够学习到其他 proposer 的提案并进行跟随，那么就有可能形成多数的接受。
proposer 如何学习呢？在正式发出提案之前，先进行一轮查询，询问 acceptor 们是否有已经接受的提案。如果查询过后，没有发现任何接受的提案，它就广播 自己的提案了。这是理想化的情况，假如已有接受的提案了，它应该跟随哪一个提案，以便整个系统快速收敛？到现在为止，提案就是值本身，而不同的值对于 proposer 来说没有什么区别，它需要额外的信息。
acceptor 不能接收每一个收到的提案，如果它接收收到的第一个提案，并接受之后收到的相同值的提案，这样会不会对上面的分裂情形产生帮助呢？并不会。
proposer1, proposer2, proposer 3 失败之后，再进行一轮查询，这时候返回的值有 v1, v2, v3。且不说选择哪一个，就算选择任意一个，继续发出 请求也不会形成多数派，因为 acceptor 那里已经不会修改接受的提案了。在 acceptor 的接受规则这里已经到头了，不能玩出新的花样了。
再次明确一下现在的情况，proposer有3个，分别是proposer-1, proposer-2, proposer-3, acceptor 有5个，分别是S1 ~ S5.
proposer-1 提出的 v1 被 S1, S2 接收； proposer-2 提出的 v2 被 S3 接收； proposer-3 提出的 v3 被 S4, S5 接收。 proposer 的工作过程已经发生了改变，为了学习在失败时追随可能已经成为多数的提案，加速共识的快速收敛，首先要进行一轮查询请求，然后根据情况再发出 一轮提案。目前我们进退两难，分裂的局面难以进行下去，整个系统陷入无效工作的循环当中。
我们能不能避免这种分裂的情况呢？proposer-1,2,3 刚开始查询的返回结果中都显示没有任何已经接收的提案，所以它们随机写入自己的提案。假如我们想让 v1 称为共识，能不能在第一轮查询的时候告知 acceptor 不要接收其他 proposer 的值？这样第二轮的时候肯定能够多数派写入成功。现在 acceptor 不仅 要区分不同的值，还要区分不同的 proposer，那么给每个把每个 proposer 的编号在查询时传递给 acceptor 吧。可是，别忘了，在分布式系统中，每个 proposer 的行为是并发的，假设 proposer-1 给一个多数派集合 Q1 发送了查询请求，这样 Q1 中每个 acceptor 都记住了 proposer-1；同时， proposer-2 给另一个多数派集合 Q2 发送了查询请求，Q2 和 Q1 肯定有交集，交集中至少有一个元素，记作 S_0。这个 S_0 到底是记住 proposer-1， 还是 proposer-2 呢？如果记住收到的第一个查询请求的 proposer，之后这个 proposer 挂掉了，那么这个 acceptor 就废掉了，无法参与投票了；所以， 记住最新的查询请求的 proposer。
第一轮查询时有必要的，首先它是一个学习共识的过程。然后我们对其附加了额外的操作，要求 acceptor 承诺不再接受其他 proposer 的提案。第一轮请求 称为 Prepare 请求。 第二轮请求称为 Accept 请求。这样对于 proposer 来说整个提案过程分为两个阶段（2-Phase）。
如果运气不好，proposer-1 在 Prepare 请求中对他许诺的 acceptor 在中途被更新的 Prepare 请求拐跑了，那么 proposer-1 将会在 Accept 请求 中收到接受到的提案，这时候应该选择哪一个跟随呢？返回的响应中可能包含proposer-1自己发出的提案。
似乎进行不下去了，让我们来看看 Paxos 在 P1 之后的进展吧。
只接受一个值会导致分裂，那么允许接收多个值吧，只是这些值要相同。这和我们的推导似乎有点相似。Paxos 算法给每个提案附加了一个编号，每个 Proposer 发出的提案的编号是严格递增的，且不同的proposer发出的提案编号没有重叠。这引出了 P2.
P2. 如果一个值为 v 的提案被接受了，那么每个更大编号的被接收的提案的值也都是 v. 与我们的推导不同的是，Paxos 给提案附加了编号。这是不太自然很难想到的地方。也许，我们的推导还需要参阅更多的资料，而不是从零开始。
P2 有两个推论:
P2_a. 如果一个值为 v 的提案被接受了，那么被 acceptor 接收的更大编号的提案的值也都是 v. P2_b. 如果一个值伪 v 的提案被接受了，那么由 proposer 发出的更大编号的提案的值也都是 v. 那么 proposer 如何学习到这个已经被接收的提案的值呢？通过 Prepare 请求，这和我们的推导吻合。P2_a 和 P2_b 分别对 acceptor 消费端和 acceptor 生产端都提出了要求。
那么前面分裂的情况解决了吗？并没有。我们仍然需要 acceptor 在 Prepare 请求时给我们一些承诺，Paxos这里导出 P2 的第三个推论：
P2_c. 对于编号为 n，值为 v 的提案被一个多数派 S 接收，则 S 中的acceptor 满足： (a) 没有任何 acceptor 接受过任何编号小于 n 的提案 (b) 在接收过的编号小于 n 的最大编号的提案的值也是 v P2_c 对 acceptor 提出了更为具体化的要求。Prepare 阶段要学习的提案就是编号小于 n 的最大提案的值；那么 acceptor 的承诺是什么，在 Prepare 请求中不接受比 n 小的请求；在 Accept 请求中，不接受编号比 n 小的请求。这就是新的规则：
P1_a. 一个acceptor接收编号为 n 的提案当且仅当它没有响应过任何编号大于n的prepare请求。 这里的响应其实就是许诺，不响应就是不许诺。</content></entry><entry><title>Paxos Simple 阅读笔记</title><url>/post/seventh/</url><categories/><tags/><content type="html">问题定义 什么是共识算法（Consensus Algorithm）：
一个集合中的每个进程都能对某个变量的值作出提案。共识算法保证在提案（proposed）的值中只有一个被选中（chosen）。如果没有值被提出，那么就没有 值被选中。如果已经有值被选中了，那么进程能够学习（learn）到这个选中的值。
共识算法的活性要求（safety requirements）：
在提案的值中只有一个能被选中 仅选择一个值 一个进程只有在值被选中后才能知道这个被选中的值 活性要求保证了某个被提案的值最终会被选中，如果一个值别选中之后，一个进程最终能够学习到这个值。
Paxos 算法中包含三类角色，分别是：
proposers, 提案者：负责对变量的值进行提案 acceptors，接受者：负责对提案进行决策 —— 接受或者拒绝 learners，学习者：在值被选中之后，进行学习 在具体实现中，一个进程可能扮演多种角色。
假设进程之间可以通过消息进行通信。Paxos 使用常见的，异步的，非拜占庭（non-Byzantine）模型：
进程以任意速度运行，可能会因为由于崩溃而失败，可能重启。因为，进程完全有可能在一个值被选中后失败，然后重启，所以必须借助持久化存储来保存 一些决策信息。 消息会花费任意上的时间，可能会重复，可能会丢失，但是绝不可能被破坏。 如何选择一个值 单个 Acceptor 最简单的方法是只有一个acceptor。一个 proposer 发送一个提案（proposal）给 acceptor，acceptor 接受（accepted）第一个收到的提案。
只有一个 Acceptor，最显而易见的问题是：如果它挂掉了，那么共识就无法进行下去。
多个 Acceptor 很自然的，我们想到使用多个 Acceptor 来选择一个值。既然有多个 Acceptor，那么 Proposer 将提案发送给多个 Acceptor。只有当足够多 的Acceptor接受了某个值，那么它才算被选中了。这是多个 Acceptor 下的选择策略。那多少才足够呢？超过半数。1/3 行不行呢？如果有 1/3 的 Acceptor 选中了某个值，另外 2/3 选中了另外一个值，这样就选中两个值，不满足算法的活性要求。那么 1/2 行不行呢？也是同样的问题。如果超过半数，根据鸽笼原理， 不可能有两个大小超过半数而没有交集的集合选中不同的值。
假设我们共有 5 个Acceptor，分别为 S1, S2, S3, S4, S5. 其中：
S1, S2, S3 选中了值 v1 S2, S4, S5 选中了值 v2 集合 {S1, S2, S3} 和 {S2, S4, S5} 之间存在交集 {S2}。如果要达成共识，即 v1 = v2 的话，S2 只能选择一个值。
因为 S1, S3 和 S2 选择相同， S4, S5 和 S2 选择相同，所以 Acceptor 之间达成了共识。
假如没有失败和消息丢失，在一个 Proposer 的情况下，并且该 Proposer 只提出了一个提案，那么这个提案应该被接受并选中。这意味着满足下面的要求：
P1. 一个 Acceptor 必须接受它收到的第一个提案 但是这个要求会导致一个问题。假设几个proposer各自提案了不同的值，导致每个acceptor都接受了一个值，但是没有一个值被大多数acceptor所接受。
P1 和 一个值被选中当且仅当被多数acceptor接受要求 acceptor 必须能够接受多个提案。这个结论看着很简单，却不是那么自然地容易得出。为什么 acceptor 只接受一个提案就不能形成共识呢？前面提到，形成共识的前提是两个多数的交集接受了同一个值。
假设我们共有 5 个Acceptor，分别为 S1, S2, S3, S4, S5. 其中：
S1, S2, S3 选中了值 v1 S2, S4, S5 选中了值 v2 加入 S2 先接受了 v1, 那么 S1, S2, S3 接受了 v1, S4 和 S5 接受了 v2，v1 被多数接受，这不是形成了共识了吗？但如果 S2 挂掉，剩下的 S1, S3 与 S4, S5 分别接收了 v1 和 v2, 此时又形成了分裂。这种情况下不能形成共识。
我们已经通过例子证明了接受单个提案容易导致单点故障，那么不妨让acceptor能够接收多个提案。
“多个提案”，acceptor 如何知道收到的两条消息是不同的提案呢？我们给提案附加一个编号，这样的话提案就由两个部分组成：
提案编号 提案的值 为了避免混淆，我们要求不同的提案必须有不同的编号。这里的不同是指不同的消息。提案的内涵得到了扩容，值被选中的条件也需要稍作调整。
一个值被选中当且仅当一个拥有该值的提案被大多数acceptor所接受。
在这种情况下，我们说提案（包含它的值）被选中。
我们允许多个提案被选中，但是保证所有被选中的提案都有相同的值。编号肯定有大小，现在保证对于某个proposer而言，后发出的提案的编号更大。 如果多个提案被选中，那么后面的提案编号更大，但是值确实和被选中的值相同。即满足：
P2. 如果一个值为 v 的提案被选中，那么每个更高编号的被选中的提案的值也是 v 为什么要限制“更大的编号”呢？“如果一个值为 v 的提案被选中，那么后面被选中的提案的值也是 v”，这样说行不行呢？这是一个疑问。
为了被选中，一个提案至少要被一个acceptor所接受。所以，为了满足 P2，我们必须满足：
P2^a 如果一个值为v的提案被选中之后，那么更大编号的由acceptor接收的提案的值也为 v. 有了 P2^a，我们仍然要满足 P1。假设一个提案被一个从未接受过任何提案的acceptor c 所接受。这时候一个新的 proposer 醒来了，发出了一个更大的 但是不同值的提案。P1 要求 c 接受这个提案，此时已经有多数接受了某个值，即已经有值被选中了，这样就违反了 P2^a。
为了同时满足 P1 和 P2^a，要求我们加强 P2^a 到 P2^b
P2^b 如果一个值为v的值已经被选中，那么任何更大的编号由proposer发出的提案的值都是v 因为一个提案是先由 proposer 发出，然后由 acceptor 接收，所以由 P2^b 可以满足 P2^a，间接满足 P2.
为了发现如何满足 P2^b，让我们考虑如何证明它成立。
假设已经有编号为 m, 值为 v 的提案被选中，那么需要证明任何编号大于 m 的编号 n 的提案的值也是 v.
我们可以在 n 上面使用数据归纳法从而简化证明。我们可以证明在假设编号在 m..(n-1) 之间的提案都有值 v 的前提下证明满足 P2^b.
当编号为 m 的编号的提案被选中时，肯定有一个包含多数的集合 C，其中的 acceptor 都接受了它。将这个情况与归纳假设结合起来，m 被选中意味着：
Every acceptor in C has accpeted a proposal with number in m..(n-1), and every proposal with number in m..(n-1) accepted by any acceptor has value v.
因为任意多数的集合 S 至少包含 C 的一个元素，我们通过维护下面的不变性来保证编号为 n 的 提案也有值 v:
P2^c 对于任意 v 和 n, 如果编号为 n, 值为 v 的提案发出后， 存在一个多数 acceptor 的集合 S 满足下面两个条件： (a) S 中没有 acceptor 接受过编号小于 n 的提案 或者 (b) v 是 S 中acceptor所接收到的编号小于 n 的最大编号的提案的值。 我们因此可以维护 P2^c 进而来满足 P2^b.
为了维护 P2^c，一个 proposer 如果想发出一个编号为 n 的提案，必须学习到编号小于 n 的最大编号的提案（如果有的话），这个提案已经或者将要被某些 多数集合的 acceptor 所接受。
proposer 要求 acceptor 不在接受任意编号小于 n 的提案。这样就形成了下面的发出提案的算法：
一个 proposer 选择一个新的提案编号 n，并向acceptor的某个集合发出请求，要求它们响应： (a) 许诺不再接受任何编号小于 n 的提案
(b) 如果有的话，返回acceptor所接受的最大的编号小于n的提案
这样的请求叫做一个 prepare 请求。
如果 proposer 收到多数 acceptor 的应答，那么它可以发出一个编号为 n, 值为 v 的提案；其中 v 是它收到的所有响应中最大编号的提案的值，或者 它自己提议的值，如果没有收到任何响应的话。 一个 proposer 发出一个提案请求 acceptor 接收它的提案。这个请求叫做 accept 请求。
上面两步描述了 proposer 的算法。acceptor 的算法是怎样的呢？</content></entry><entry><title>Paxos 算法资料整理</title><url>/post/fifth/</url><categories/><tags/><content type="html">Basic Paxos Paxos Made Simple - Leslie Lamport
可靠分布式系统-paxos的直观解释
可靠分布式系统-paxos的直观解释.pdf
Multi Paxos Implementing Replicated Logs with Paxos - Diego Ongaro
Paxos lecture (Raft user study)
用paxos实现多副本日志系统&amp;ndash;basic paxos部分
用paxos实现多副本日志系统&amp;ndash;multi paxos部分</content></entry><entry><title>一些Windows下小工具推荐</title><url>/post/third/</url><categories/><tags/><content type="html">第三篇，我想来聊一下windows10环境下的好用的小工具。
Listary：文件搜索工具。速度非常快，搜索匹配度高。最近更新到 6.x 版本，界面升级了。双击 Ctrl 唤起。 uTools：应用启动工具。Alt + 空格键 唤起。再也不需要自己去桌面上找图标然后双击了。 WizTree：磁盘分析工具。分析非常快，以百分比的形式显示哪些文件夹和文件占用磁盘比例最大，让我们释放磁盘空间时有的放矢。 Sublime Text：文本编辑器。功能不是很强大，但是打开非常快。打字交互做得很好，适合作为普通文本编辑器。默认主题也很好看。 我最常用的就是这几个软件呢。东西不在多，也需要精，趁手即可。</content></entry><entry><title>Java 开发者的磁盘管理经验</title><url>/post/second/</url><categories/><tags/><content type="html">Hugo 有时候会有点问题，看不见 post.
今天我想来聊聊 Java 开发者的一些电脑存储管理的经验。
第一呢，是IDEA的 idea.properties 文件中的几个路径，比如插件存放的路径，索引的路径。这些都可以修改。如果使用默认配置的话，时间长了，C 盘很容易被占满。
第二个呢，是关于 Maven 的本地仓库。也不要放在 C 盘。IDEA 每次打开新的工程师会使用自己默认的 Maven 配置，我们可以新建一个打开项目的模板，在里面配置自己的Maven仓库位置和配置。
第三个，关于 JDK 版本的管理。我们可能会用到多个 JDK，从 1.6, 1.8, 11 到 17 等。可以用一个专门的文件夹来存放JDK。</content></entry><entry><title>About</title><url>/about/</url><categories/><tags/><content type="html">关于</content></entry></search>