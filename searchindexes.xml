<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Ubuntu 22 虚拟机扩容</title><url>/post/linux_space_extend/</url><categories/><tags/><content type="html">首先关闭虚拟机，然后给虚拟机磁盘扩容。
fdisk /dev/sda 进入之后按 d 选择删除 sda 现存的分区，从最大分区开始删，一直删到第一个。
然后新建分区：n, p, 一路回车
之后 reboot
在进入 ：
resize2fs /dev/sda4 lvextend -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv resize2fs /dev/sad4 是扩充最大编号的分区</content></entry><entry><title>Paxos 共识算法（第二次尝试）</title><url>/post/20230101_03/</url><categories/><tags/><content type="html">共识问题 对于一个变量来说，假设有一系列的进程都可以对它的值发出提议。共识（consensus）算法保证在这些提议（proposed）的值中只有一个能被选中（chosen）。 如果没有提议，那么就不会有值被选中。如果一个值被选中之后，进程能够学习到（learn）这个被选中的值。
经典的共识算法主要有 Paxos 和 Raft。今天我们介绍 Paxos 算法。
共识算法应用案例 Etcd Etcd 是 CoreOS 基于 Raft 协议开发的分布式键值对存储 (key-value peer store) ，设计用来可靠而快速的保存关键数据并提供访问。
etcd 可用于：
共享配置 服务发现 分布式锁或一致性保障 分布式数据队列 分布式通知和协调 集群选举 微信 PhxPaxos PhxPaxos是腾讯公司微信后台团队自主研发的一套基于Paxos协议的多机状态拷贝类库。 它以库函数的方式嵌入到开发者的代码当中， 使得一些单机状态服务可以扩展到多机器，从而获得强一致性的多副本以及自动容灾的特性。 这个类库在微信服务里面经过一系列的工程验证，并且我们对它进行过大量的恶劣环境下的测试，使其在一致性的保证上更为健壮。
OceanBase OceanBase 数据库使用 Paxos 的优化 Multi-Paxos 实现多副本数据同步以及集群的高可用。
Apache Kafka 使用 KRaft 替换 ZooKeeper Apache Kafka 3.3 Replaces ZooKeeper with the New KRaft Consensus Protocol
KRaft is the consensus protocol developed to allow metadata management directly in Apache Kafka. This greatly simplifies Kafka’s architecture by consolidating responsibility for metadata into Kafka itself without the requirement of a third-party tool like Apache ZooKeeper.
Apache Kafka 替换 ZooKeeper 为 自身实现的 KRaft 协议用于元数据的管理。
故障模型 我们假设进程之间通过消息进行通信，并使用异步的、非拜占庭式的故障模型：
进程可能会以任意的速度运行，可能会崩溃，可能会重启。值别选中之后然后进程重启了，这种情况完全有可能，所以共识算法必须要采取持久化存储来保证进程 崩溃和重启之后仍然能够记住某些决策信息。
进程发送的消息送达的耗时是不确定的，可能会花费非常长的时间，可能会重复、丢失， 但是绝不会被篡改（非拜占庭）。
安全性要求 共识算法的安全性要求如下：
提议中的值才能被选中 只有一个值能被选中 只有被选中的值被确定下来之后，进程才能学习到这个值 活性要求 只要超过半数的server能正常工作，并且消息也能在合理的延时范围内达到，那么系统就能够正常工作，得出正常的结果。正常工作包含两个方面：
总是确定最终选定一个值，而不是一直处于一个没有值被选中的状态中。 如果一个值被选中（chosen），那么其他的server最终必然能够得知这个值。 Paxos 算法 基本组件 Paxos 算法中需要两个组件相互配合：提议者（proposer）和 接受者（acceptor）。
提议者（proposers）：系统的主动部分，接收客户端的请求，根据请求向其他的server提议特定的值，尝试让其他server接受并最终选定这个值。 接受者（acceptors）：系统的被动部分，接收提议者的请求并做出响应。响应的结果可以看成一次投票，表示接受者是否接收提议者的提议。 下面我们简单推导一下Paxos算法的流程。
单个 acceptor 只有一个 acceptor 来处理所有的提议。当不同的提议提交之后，acceptor 从中选择一个值作为选定值。但是，这个唯一的 acceptor 挂掉之后，我们就 无法得知选中的值了。
多个 acceptor 为了解决acceptor单点故障的问题，我们采用多个 acceptor，并采用朴素的少数服务多数的原则，如果一个提议被多数acceptor接受之后，就认为是被选定了。 这样的话，如果一个 acceptor 宕机了，剩下的acceptor仍然能告诉我们被选定的值是什么。
那么acceptor采用怎样的策略接受提议呢？我们不妨使用最简单方案：接受它收到的第一个提议。
但是这样可能发生如图所示的分裂的情况，没有任何值被过半的acceptor所接受，没有任何中被选中，违反了算法的安全性要求。
如果acceptor可以改变自己的想法，接受多个不同的值呢？
不幸的是，此时可能产生多个被选中的值。
这个问题的解决方案是：proposer 在提议之前，如果发现一个值已经被选定，那么必须抛弃自己的提议，只能提议被选定的值。所以 s5 在提议之前，需要先 确定是否已经有其他值被选中。所以在正式提案之前先进行一次查询，这个方案就是二阶段协议 (2-phase protocol).
两阶段协议仍然不足以解决一些问题场景。
如图，S1 和 S5 经过查询之后碰巧都发现 acceptor 没有选定的值，所以发出自己的提议。于是，又出现两个值被选中的情况。
这个问题的解决方案是：一旦我们选定了一个值，其他的不同的提议应该被 acceptor 拒绝并最终被整个系统淘汰掉。在这个例子中，s3 已经先接受了 s5 的提议，需要以某种方式拒绝掉 s1 的提议。
为了达到这个目的，我们给所有的提议附加一个编号，对他们进行排序。如果 acceptor 已经接受了更新的提议，那么根据编号大小需要拒绝掉更老（更小编号） 的提议。
也就是：
我们需要二阶段协议，在正式提议之前，先检查是否有其他值被选中，如果有，就抛弃掉自己的值，改选已经选定的值。 所以的提议要有序。如果acceptor已经接受了新的提议，就应该拒绝掉老的提议。 Paxos 算法流程 Paxos 算法分为两个阶段，分别叫做 Prepare 阶段和 Accept 阶段。
Prepare 阶段：proposer 尝试提议时，先广播 prepare 请求，到达两个目的：
找到已经被选定的值 阻塞掉还没有完成的旧的提议 Accept 阶段：proposer 广播 accept 请求，让系统接收一个特定的值，如果有过半的acceptor回复接受，那么就确定这个提议被选中了。
我们来详解解释一下这张图。
proposer 想要提议某个值时，首先要生成一个提案编号 n，这个编号必须没有使用过，而且比当前proposer以往使用的编号都大。
首先我们进入 prepare 阶段。在此阶段，我们的prepare请求中只有一个编号 n。当acceptor 接收到 prepare 请求时，做两件事情：
承诺不会接受比 n 编号还小的提议。为此，acceptor 保存一个 minProposal 值，表示 acceptor 第二阶段能够接收的值的提议编号必须大于等于它。 acceptor 同时检查n是否大于 minProposal，如果是，则更新 minProposal = n. 如果之前已经接受了一个提议，需要将其作为prepare请求的响应返回给proposer。因此，acceptor 必须记录下该提案的编号和值，分别为 acceptedValue 和 acceptedProposal。 Proposer 发出prepare请求之后，等待acceptor响应，至少有过半的acceptor响应之后，才能进入第二阶段。如果acceptor收到的响应中包含接受的提案， 它将从中选择一个编号最大的提案的值作为自己的提案的值，否则使用自己的值。
proposer 进入第二阶段后，发出的 acceptor 请求中携带两个中，编号和提案的值，编号就是 prepare 请求中的编号。
acceptor 接收到 Prepare 请求后，比较编号与 minProposal 的值，如果大于等于它，则更新 minProposal的值为n，并且替换自己 acceptedValue 为请求中的值。如果小于则直接拒绝。不管acceptor是接受还是拒绝这个提议，acceptor都会返回自己的minProposal值给proposer。
proposer在发送完accept请求后，就等待acceptor的响应。直到过半数的acceptor响应之后，proposer才能决定下一步做什么。 如果proposer收到的响应中有拒绝（rejection），那proposer就放弃此轮paxos，回到第一步重新再来。 如果proposer收到了过半数的acceptor的接受(accept)，那么proposer就可以确定，自己提交的值被选定了。 proposer通过比较acceptor返回的结果值（即acceptor的minProposal值）来确定自己到底是被拒绝还是被接受了： 如果结果值大于自己prepare时的提议号，那自己就是被拒绝了；否则，自己就是被接受了。
Paxos算法应对冲突的案例 不同 proposer 的 prepare 请求和 accept 请求之间是高度并行化的，所以不同提议之间会发生很多竞争。
我们来看一下basic paxos在几种特定的竞争状态下，怎么保证正常工作的。
需要明确的一点是，如果 paxos 能够因为竞争而出问题，关键的时间点就发生在 proposer 第二次发出 prepare 请求的时刻。为什么是第二次呢？ 如果第二次prepare都没有，哪来竞争呢？如果第二次prepare时能顺利被解决，那第三次prepare的发出应该可以类推，又变成了第二次 prepare 请求。 我们知道所有的提议都是被按顺序编号的，所以我们要关注的就是编号较大的那次prepare。
已经有值被选中 这里的图示显示的是acceptor的视角，P 3.1 表示这是一个编号为 3.1 的 Prepare 请求；A 3.1 X 表示这是一个编号为 3.1，值为 X 的 accept 请求。
图中S1 和 S5 先后发出了提议。
S1, S2, S3 已经就 X 达成了共识；S5 在向 S3, S4, S5 发送 prepare 的第一阶段中，获取到 X 的提议，于是放弃自己的值，该用 X，于是原先由 3个acceptor接受的值现在被巩固到被所有acceptor接受。
原先的值尚未被选中 这里分为两种情况：
新的 proposer 能看到原先的值 与第一种情况类似，S5 在prepare阶段发现 X 的存在，并使用 X 作为自己的提案的值。
新的 proposer 未看到原先的值 S5 将使用它自己的值，原先旧的提议将被终止。S1 向 S3 发出的 accept 请求由于编号小于 4.5 而被拒绝。S5 提议的值被选中。
Paxos算法应对崩溃的场景 acceptor 在 prepare 阶段崩溃 只要超过半数的acceptor仍可以正常响应，算法仍然能正常继续下去。
acceptor 在 accept 阶段崩溃 只要超过板书的acceptor仍然能正常响应，算法仍然能正常继续下去。
proposer 在 prepare 阶段崩溃 如果 proposer 在发出任何消息前崩溃，那么就和它从未运行过效果是一样的。
如果它已经发出了一些 prepare 请求，某些 acceptor 会发回响应，然而没有后续的 accept 请求。不过其他的节点也在继续Paxos算法，并使用更大 的编号来废弃掉失败的提议；如果编号没有超过它的话，那么只能自己选择一个更大的编号来阻塞掉之前的旧的提议。
如果 proposer 在 accept 阶段失败，但是至少被一个acceptor接受了。那么后续proposer在prepare请求的响应中可能会发现这个提议，将其作为自己的 提议的值，帮助前者完成终止的Paxos过程。
其他 如何读取到达成共识的值 运行一轮 Paxos 算法过程
活性保证 Paxos 可能会形成活锁，如图：
解决办法有两个：
proposer 如果发现自己的提议被拒绝，那表明有其他proposer也在想设定这个值，那么就随机地等待一段时间， 让另一个 proposer 可以有更大的机会来完成整个流程，最终把这个值确定下来 从 proposer 中选出一个 leader，确保一个时间段内，只有一个 proposer，避免活锁的发生。 参考：
[1] 用paxos实现多副本日志系统&amp;ndash;basic paxos部分
[2] Implementing Replicated Logs with Paxos - Diego Ongaro</content></entry><entry><title>Paxos 共识算法（第一次尝试）</title><url>/post/20230101_02/</url><categories/><tags/><content type="html">共识问题 对于一个变量来说，假设有一系列的进程都可以对它的值发出提议。共识（consensus）算法保证在这些提议（proposed）的值中只有一个能被选中（chosen）。如果没有提议，那么就不会有值被选中。如果一个值被选中之后，进程能够学习到（learn）这个被选中的值。
共识算法的安全性要求如下：
提议中的值才能被选中被 只有一个值能被选中 只有被选中的值被确定下来之后，进程才能学习到这个值 在 Paxos 算法中主要有两种类型的角色：
proposers：提案者，负责对变量的值发出提案。 acceptors：接受者，负责对提案进行决策。 在实际的实现当中，一个进程可能在不同时刻担任不同的角色。
我们假设进程之间通过消息进行通信，并使用异步的、非拜占庭式的故障模型：
进程可能会以任意的速度运行，可能会崩溃，可能会重启。值别选中之后然后进程重启了，这种情况完全有可能，所以共识算法必须要采取持久化存储来保证进程崩溃和重启之后仍然能够记住某些决策信息。 进程发送的消息送达的耗时是不确定的，可能会花费非常长的时间，可能会重复、丢失，但是绝不会被篡改（非拜占庭）。 如何选择一个值 最简单的方法是只有一个acceptor。一个 proposer 发送一个提案（proposal）给 acceptor，acceptor 接受（accepted）第一个收到的提案。 只有一个 Acceptor，最显而易见的问题是：如果它挂掉了，那么共识协议就无法进行下去。
为了避免单点故障，我们采用使用多个 acceptor 才参与决策。proposer 将提案请求发送给每个 acceptor，如果其中多数的acceptor接受了它的提案，那么该提案就被选中了。这里的多数是指超过1/2。这时有没有可能出现两个值都被选中了呢？我们假设存在这种情况，被选中的值分别为 v1 和 v2，接受它们的acceptor集合分别为 S1 和 S2，且 v1 不等于 v2. 由于 S1 和 S2 都是多数的acceptor集合，它们之间必有交集。如果 v1 和 v2 都被选中了，说明它们的交集 S 中的acceptor至少接受了两个不同的提案。这就违反了算法的安全性要求，我们希望有且只有一个值被选中，因此我们需要对 acceptor 的决策行为作出限制，即：acceptor 最多只能接收一个提案。
此时，我们需要明确一下提案的内容，目前为止，提案就是值对变量的取值，不包含其他内容。
此时，我们可以回答小节的标题“如何选择一个值”？答案就是：当acceptor中的多数接受了（accepted）一个提案时，它就被选中（chosen）了，它就是acceptor和proposer达成的共识。
Paxos 算法的推导 现在我们只知道提案被选中的判定方式，而算法对于 acceptor 和 proposer 施加怎样的限制以及两者交互的协议如何设计还不得而知。下面我们将从最简单的情景出发，逐步推导出整个算法的流程。
假设我们的算法设计已经完成，那么它肯定能满足一些最简单的场景。
从最简单的场景出发 假设我们现在只有一个 proposer，它只发出了一个提案，在没有消息丢失或者进程崩溃的情况下，我们想让这个唯一的提案被选中。这听起来有点难以理解。如果这样想：整个系统里面只有一个提案，那它成为共识不是很自然的事情吗？毕竟，没有任何其他人提出任何其他的意见。这里，我们有意忽略了时间这个要素，但是可以继续假设一个极端的情形，在无限远的时间内，只有这一个提案，我们必须要接受它。这就对于 acceptor 提出了一个最简单的决策要求：
P1. 一个 Acceptor 必须接受它收到的第一个提案
在上面极端的情形中，如果 acceptor 不接受它收到的这个唯一的提案，我们便不能形成这各想当然的唯一的共识。但是为什么是“第一个”呢？在只有一个提案的情况，以“第一个”和“最后一个”来描述它达到的顺序同样正确。因为“最后一个”隐含了对于时间的要求，比如“在3分钟内的最后一个”，“在过去7天内的最后一个”，然而，我们的算法并不对时间作出限制，所以判定“最后一个”是不可能的。
P1 的要求如此简陋，我们可以轻而易举地找到它的一个问题场景：
在如图所示的场景中，S1 到 S5 既是proposer 也是 acceptor，它们可以向自身发出提案和接收自身的提案。proposer 和 acceptor 是同一个进程的情况是比较常见的。
S1 向 S1, S2 发出 red 的提案，并被接受；S3 向 S3 和 S4 发出 blue 的提案，并被接受；S5 向自身发出提案并被接受。此时，任意一种值都不能形成多数，如果 S1 再像向 S3 发出请求，由于 S3 已经接受了 blue（收到的第一个提案），而且 red 不等于 blue，S4 和 S5 也是如此。所以 S1 提案的 red 在第一轮提案中不可能成为共识; S3 和 S5 也同样失败了。S1 再次发次提案行不行呢？由于acceptor不能撤销它接受的提案，所以除了 S1 和 S2 之外它不可能再取得其他 acceptor 的接受。共识过程陷入了死局。
先协商再提案 如果 S1 在正式进行提案之前先和所有的acceptor打个招呼，等会我提案的时候你只接受我的，其他 proposer 都要拒绝掉。我们将打招呼的请求称为 Prepare 请求，将正式的提案请求称为 Accept 请求。
为了正确地履行给 proposer 的承诺，acceptor 必须要能够区分不同的 proposer。为此，proposer 可以将自己的唯一标志发送给 acceptor，并让它记住。比如 S1 的标志就是 1，S3 的标志就是 3。问题又来了，在 Prepare 请求中 acceptor 记住的 proposer 能不能更改呢？这个问题似乎和提案的值能不能更改有点类似。必须要能更改。假如 S2 在 Prepare 请求中承诺只接受 S1 的提案，结果 S1 在这时候突然挂掉了，此后再也没有醒来。S2 这个决策者就这样干巴巴地等着 S1 的 Prepare 请求，并履行承诺拒绝其他 proposer 的请求，等于 S2 陷入了一个死锁的情况，资源无法释放。如果要能更改的话，从锁的角度来说，S2 就变成了一个可抢占的锁。
可是如果在 Prepare 请求中 acceptor 记住的 proposer 可以更改的话，岂不是 acceptor 的承诺是没有保证的吗？例如：S1 前脚收到了 S2 的承诺，后脚 S2 就又答应了 S3 了。干脆让 S2 承诺之后拒绝其他 proposer 的 Prepare 请求算了。但这样又会回到之前的说的由于 proposer 故障导致 acceptor 一直被占用的情况。
又要能变，又不能随意地变？等等，acceptor 的承诺一直变化的话也许对于结果没有影响。
我们继续看看 Accept 请求，S2 此时在将自己的标志加上提案发送给所有的acceptor，如果幸运的话，多数 acceptor 接受了它的提案，从返回的响应里面，S2 得知自己的提案已经被选中。那么问题又来了，其他 proposer 如何学习到这个值呢？在 Accept 请求的回应中或者更早一点在 Prepare 请求的响应中，如果一个 acceptor 已经接受了某个提案，将它返回给 proposer，然后 proposer 从中选取一个提案的值并使用它发出 Accept 请求，这样系统就能对变量的值的认知快速收敛。
下面我们明确一下这两个请求的过程：
Prepare 请求：proposer 将自己的标志发给所有 acceptor，如果响应中包含提案的话，就从中选择一个值作为自己的提案。
Accept 请求：proposer 将自己的标志加上提案的中发送给所有 acceptor，如果半数以上的 acceptor 回复接受的话，那么 proposer 就认定自己的值被选中。否则重复步骤1.
在 Prepare 请求的响应中，proposer 可能接收到多个提案的值，从中选择哪一个进行跟随才能更快加速共识收敛呢？ 或者说，这些不同的提案哪一个更有利于共识的形成？需要明确的是，我们对提案的值没有偏好，各个 proposer 之间是平等的，我们不会偏爱某个值。因此，必须对提案附加一些额外的信息来定制一些规则加速共识收敛。
给提案附加编号 如果我们给每个提案一个编号，类似于数据库中的主键，然后在选择提案进行追随时选择那个编号最大的，仅仅这样做就可以了吗？
现在我们的提案不仅仅是值那么简单，还有编号。所以，完整的提案结构包含两个部分：提案的编号，提案的值。
假设我们已经知道了被选中的值，怎么让它在整个共识协议过程中逐渐地披露出来呢？
我们回头想一想，proposer 在 Prepare 请求阶段收到的提案中随机选一个作为自己提案的值，这样行不行呢？有可能行，但我们的要求是算法必须能够正确地得到答案，而不是有时行，有时不行。
如果 proposer 选择了那个编号最大的提案作为自己的提案，acceptor 应该也要修改一下规则以保证更大编号的提案优先被接受。发生在多个进程之间的算法过程也可以看做协议，需要多边都作出举措以促进结果的形成。
acceptor 目前的决策规则是能够接收相同值的提案，为了使得编号更大提案有更大的优先级，我们需要调整一下规则：
P2. 如果一个值为 v 的提案已经被选中，那么任何更大编号的被接收的提案的值也是 v.
那么更小编号的提案呢？那就需要拒绝掉，要不然使用编号大小形成的优先级无法保证。我们的初衷是利用编号形成的优先级规则帮助整个系统更快地达到共识，换句话说，我们要让已经某个多数派接收的值更快地传播到系统内的所有节点上。
由于只有 acceptor 才能对提案进行接受或者拒绝，很自然地，我们由 P2 推导出：
P2_a：如果一个值为v 的提案已经被选中，那么任意acceptor接受的更大编号的提案的值都是 v。
“更大的”编号总有一个标准，它比较就是这个已经接受的提案的编号。
我们的规则变得越来越复杂，但是它仍然要满足最简单的场景。试想：假设在一个提案被选中后，有一个proposer经过prepare阶段后碰巧发现acceptor还没有接收过任意提案，于是便发出了更大编号的提案给了一个从未接受过任何提案的acceptor，而此时其他acceptor已经对某个提案形成多数，按照 P1，这个acceptor必须接受当前的提案，可是这又违反了 P2_a。为了同时满足 P1 和 P2_a，必须对 proposer 提出的提案进行限制：
P2_b：如果一个值为v的提案已经被选中，那么任意proposer发出的更大编号的的提案的值都是 v.
可是，一个proposer在正式提案之前如何得知已经被选中的值呢？这又回到了我们说到的从 Prepare 请求的响应中挑选一个提案的问题了 ———— 选择编号最大的那个。
目前为止的流程梳理 从 proposer 的角度：
Prepare 阶段：proposer 向所有 acceptor 发送请求，要求它们只接受自己的提案。在收到的响应中如果有提案，选择那个编号最大的提案的值作为自己的提案的值；如果没有的话，使用自己的值。
Accept 阶段：proposer 向所有 acceptor 发送提案请求，包含proposerId、提案编号和提案的值。要求它们接受自己的提案。如果收到半数以上的接受恢复，就认为自己的提案成为了共识。
从 Acceptor 的角度：
收到 Prepare 请求：将proposerId 存储下来，如果已经有接受的提案，返回给proposer。
收到 Accept 请求：如果已经有接受的提案，并且当前请求的编号大于当前接受的提案的编号，就接受该提案，返回OK。如果小于接受的提案的编号，就拒绝。如果没有接受过任何提案，且请求的 proposerId 与存储的 proposerId 相同，接受该提案，返回 Ok；否则，返回拒绝响应。
如果我们将 proposerId 从请求参数中移除，仅仅使用提案的编号，那么算法流程如下：
从 proposer 的角度：
Prepare 阶段：proposer 向所有 acceptor 发送请求，要求它们不能接收比当前编号小的提案。在收到的响应中如果有提案，选择那个编号最大的提案的值作为自己的提案的值；如果没有的话，使用自己的值。
Accept 阶段：proposer 向所有 acceptor 发送提案请求，包含提案编号和提案的值。要求它们接受自己的提案。如果收到半数以上的接受恢复，就认为自己的提案成为了共识。
从 Acceptor 的角度：
收到 Prepare 请求：如果有接受的提案，且编号比当前请求小，更新存储的编号，回复OK，并带上接收的提案；如果编号比当前请求大，则拒绝当前的prepare请求，回复拒绝。如果没有接收的提案，且没有接收过 prepare 请求，储存当前的编号；如果已经收到过 Prepare 请求，如果编号被当前请求大，则拒绝当前的prepare请求；否则，更新存储的编号。
收到 Accept 请求：如果编号大于存储的值，则接收值；</content></entry><entry><title>理解Paxos算法的几种建模方法</title><url>/post/20221229_01/</url><categories/><tags/><content type="html">从并发编程锁的角度 Paxos made simple 论文导读
两阶段是先加锁再操作的过程； 引入编号是抢占锁的设计 多数派是为了获取集群的锁（鸽笼原理） 选择最大编号的提案是为了快速收敛 从多数派写的角度 可靠分布式系统-paxos的直观解释
Request promise before write 从原论文的角度 从零开始推导，不断加强约束，最后得到完整的算法过程。
https://people.cs.rutgers.edu/~pxk/417/notes/paxos.html</content></entry><entry><title>Understanding Paxos</title><url>/post/understanding_paxos/</url><categories/><tags/><content type="html"> https://people.cs.rutgers.edu/~pxk/417/notes/paxos.html
The Consensus Problem Suppose you have a collection of computers and want them all to agree on something. This is what consensus about; consensus means agreement.
Consensus comes up frequently in distributed system design. There are various reasons why we want it: to agree on who gets access to a resource (mutual exclusion), agree on who is in charge (elections), or to agree on a common ordering of events among of a collection of computers (e.g. what action to take next, or state machine replication).
Replication may be the most common use of consensus. We set up collections (clusters) of servers, all of which will have replicated content. This provides fault tolerance: if any server dies, others are still running. It also provides scale: clients can read data from any available server although writing data will generally require the use of all servers and not scale at well. For many applications, though, reads far outnumber writes. To keep the content replicated, we have two design choices. We can funnel all write requests through one coordinator, which will ensure in-order delivery to all replicas or we can send updates any system but that system will coordinate thoses update with its replicas to ensure that all updates are applied in the same order on each replica. In the first case, we need consensus to elect that coordinator. In the second case, we need to run a consensus algorithm for each update to ensure that everyone agrees on the order.
The consensus problem can be stated in a basic, generic manner: One or more systems may propose some value. How do we get a collection of computers to agree on exactly one of those proposed values ?
The formal properties for asynchronous consensus are:
Validity: only the proposed values can be decided. If a process decides on some value, v, then some process must have proposed v. Uniform Agreement: no two correct processes (those that do not crash) can decide on different values Integrity: each process can decide a value at most once. Termination: all processes will eventually decide on a result Paxos Paxos is an algorithm that is used to achieve consensus among a distributed set of computers that communicate via an asynchronous network. One or more clients propose a value to Paxos and we have consensus when a majority of systems running Paxos agrees on of the proposed values. Paxos is widely used and is legendary in computer science it is the first consensus algorithm that has been rigorously proved to be correct.
Paxos simply selects a single value from one or more values that are proposed to it and lets everyone know what that value is. A run of the Paxos protocol results in the selection of single proposed value. If you need to use Paxos to create a replicated log (for a replicated state machine, for example), then you need to run Paxos repeatedly. This is called multi-Paxos.
Paxos provides abortable consensus. This means that some processes abort the consensus if there is contention while others decide on the value. Those processes that decide have to agree on the same value. Aborting allows a process to terminate rather than be blocked indefinitely. When a client proposes a value to Paxos, it is possible that the proposed value might fail if there was a completing concurrent proposal that won. The client will then have to propose the value again to another run of the Paxos algorithm.
Our assumptions for the algorithm are:
Concurrent proposals: One or more systems may propose a value concurrently. If only one system would propose a value then it is clear what the consensus would be. With multiple systems, we need to select one from among those values. Validity: The chosen value that is agreed upon must be one of the proposed values. The servers cannot just choose a random number. Majority rule: Once a majority of Paxos servers agrees on one of the proposed values, we have consensus on that value . This also implies that a majority of servers need to be functioning for the algorithm to run. To survive m failures, we need 2m + 1 systems. Asynchronous network:The network is unreliable and asynchronous : messages may get lost or arbitrarily delayed. The network may also get partitioned. Fail-stop faults: System may exhibit fail-stop faults. They may restart but need to remember there previous state to make sure they do not change their mind. Failures are not Byzantine. Unicasts: Communication is point-to-point. There is no mechanism to multicast a message atomically to the set of Paxos servers. Announcement: Once consensus is reached, the results can be make known to everyone. What we need in a distributed consensus protocol We have an environment of multiple systems (nodes), connected by a network, where one or more of these nodes may concurrently propose a value (e.g., perform an operation on a server, select a coordinator, add to a log, whatever&amp;hellip;). We need a protocol to choose exactly one value in cases where multiple competing values may be proposed.
We will call the processes that are proposing values proposers. We will also have processes called acceptors that will accept these values and help figure out which one value will be chosen.
Multiple proposers, single acceptor The simplest attempt to design a consensus protocol will use a single acceptor. We can elect one of our systesm to take on this role. Multiple proposers will concurrently propose various to a single acceptor. The acceptor chooses one of those proposed values. Unfortunately, this does not handle the case where the acceptor crashes. If it crashes after choosing a value, we will not know what value has been chosen and will have to wait for the acceptor to restart. We want to design a system that will be functional if the majority of nodes are running.
Fault tolerance: multiple acceptors To achieve fault tolerance, we will use a collection of acceptors. Each proposal will be sent to at least a mojority of these acceptors. If a quorum, or majority, of these acceptors chooses a particular proposed value (proposal) then that value will be considered chosen. Even if some acceptors crash, others are up so we will know the outcome. If an acceptor crashes after it accepted a proposal, other acceptors know that a value was chosen.
If an acceptor simply accepts the first proposed value it receives and cannot change its mind, it is possible that we may have no majority of accepted value. Depending on the order in which messages arrive at various acceptors, each acceptor may choose a different value or small groups of acceptors choose different values such that there is no majority of acceptors that choose the same proposed values. This tells us that acceptors may need to change their mind about which accepted value to choose. We want a value to be chosen only when a majority of acceptors accept the value.
Since we know that an acceptor may need to change its mind, we might consider just having an acceptor accept any value given by any proposer. A majority of acceptor may accept a value, which means that value is chosen. However, anothoer server may also tell a majority of acceptors to accept another value. Some acceptors will receive both of these proposals because to have a mojority means that both sets of proposals have at least one acceptor in common. That means at least one acceptor had to change its mind about what value is ultimately chosen, violating the integrity property. Once we choose a value, there is no going back.
To fix this, instead of just having a proposer propose a value, we will first ask it to contact a majority of acceptors and check whether a value has already chosen. If it has, then the proposer must propose that chosen value to the other acceptors. To implement this, we will need a two-phase protocol; check first and then provide a value.
Asking a proposer to check is not sufficient. Another proposer may come along after the checking phase and propose a different value. What if that second value is accepted by a majority and then the acceptors receive requests from the first proposer to accept its value? We again end up with two chosen values. The protocol needs to be modified to ensure that once we accept a value, we will abort competing proposals. To do this, Paxos will impose an ordering on proposals. Newer proposals will take precedence over old ones. If that first proposer tries to finish its protocol, its request will fail.
How Paxos works The case of characters Paxos has three entities:
Proposers: Receive requests (values) from clients and try to convince acceptors to accept there proposed values. Acceptors: Accept certain proposed values from proposers and let proposers know if something else was accepted. A response from an acceptor represents a vote for a particular proposal. Learners: Announce the outcome In practice, a single node may run proposer, acceptor, and learner roles. It is common for Paxos to coexist with the service that requires consensus (e.g., distributed storage) on a set of replicated servers, which each server taking on all three roles rather than using separate servers dedicated to Paxos. For the sake of discussing the protocol, however, we consider these to be independent entities.
What Paxos does A client sends a request to any Paxos proposer. The proposer then runs a two-phase protocol with the acceptors. Paxos is a majority-wins proptocol. A majority avoids split-brain problems and ensures that if you made a proposal and asked over 50% of the systems if somebody else made a proposal and they all reply non then you know for certain that no other system could have asked over 50% of the systems received the same answer. Because of this Paxos requires a majority of its servers to be running for the algorithm to terminate. A majority ensures that there is at least one node in common from one majority to another if servers die and restart. The system requires 2m+1 servers to tolerate the failure of m servers. As we shall see, Paxos requires a majority of acceptors. We can have one or a smaller number of proposers and learners.
Paxos acceptors cannot forget what they accepted, so they need to keep track of the information they received from proposers by writing it to stable storage. This is storage such as flash memory or disk, whose contents can be retrieved even if the process or system is restarted.
The Paxos protocol (initial version) Paxos is a two-phase protocol, meaning that the proposers interact with the acceptor twice. At a high level:
Phase 1: A proposer asks all the working acceptors whether anyone already received a proposal. If the answer is no, propose a value.
Phase 2: If a majority of acceptors agree on to this value then that is our consensus.
Right now, we will examine the mostly failure-free case. Later, we will augment the algorithm to correct for other failures.
When a proposer receives a client request to reach consensus on a value, the proposer must create a proposal number. This number must have two properties:
It must be unique. No two proposers can come up with the same number. It must be bigger than any previously used identifier used in the cluster. A proposer may use an incrementing counter or use a nanosecond-level timestamp to achieve this. If the number is not bigger than one previously used, the proposer will find out by having its proposal rejected and will have to try again. Prepare 请求的作用：
查找到可能已经选中的值。
帮助未完成的proposal继续完成提案
避免造成分裂的情况，比如 {S1, S2}, {S3}, {S4, S5}，先和 acceptor 打好招呼，不要接收比我编号更小的。比我更大的可以，因为当前 proposer 可以会挂掉，在它重启后可以选择一个更大的编号来中断之前未完成的提案过程；或者，其他的proposer替我继续这未完的旅程。
Failure examples Acceptor fails in phase 1 Suppose an acceptor fails during phase 1. That means it will not return a PROMISE message. As long as the proposer still gets response from a majority of acceptors, the protocol can continue to make progress.
Acceptor fails in phase 2 Suppose an acceptor fails during phase 2. That means it will not be able to send back an ACCEPTED message. This is also not a problem as long as enough of the acceptors are still alive and will respond so that the proposer or learner receives responses from a majority of acceptors.
Proposer fails in the Prepare phase If the proposer fails before it sent any messages, then it is the same as it did not run at all.
What if the proposer fails after sending one or more PREPARE msgs? An acceptor would have sent PROMISE responses back but no ACCEPT messages would follow, so there would be no consensus. Some other node will eventually run its version of Paxos and run as a proposer, picking its own ID. If the higher ID number works, then the algorithm runs. Otherwise, the proposer would have its request rejected and have to pick a higher ID number.
What if the proposer fails during the ACCEPT phase? At least one ACCEPT message was sent. Some another node proposes a new message with PREPARE(higher-ID). The acceptor responds by telling that proposer that an earlier proposal was already accepted. PROMISE(higher-ID, &amp;lt;old_ID, Value&amp;gt;)
If a proposer gets any PROMISE responses with a value then it must choose the response with the highest accepted ID and change its own value. It sends out: ACCEPT(higher-ID, Value)
If proposer fails in the ACCEPT phase, any proposer that takes over finishes the job of propagating the old value that was accepted.</content></entry><entry><title>Basic Paxos Deduction From single Proposer's Perspective</title><url>/post/eight/</url><categories/><tags/><content type="html">Paxos 算法的精髓在于其推导的过程。
Paxos 算法中本质上只需要两种角色：proposer 和 acceptor。故事就发生在这两个角色之间。
在正式开始推导之前，需要明确的一点是：何种情况下谁认为达成了共识？明确“谁”的主体意味着我们需要切换视角，从 proposer 的角度，还是从 acceptor 的角度，或是从上帝的视角？答案是我们要从 proposer 的角度来明确当前系统是否已经达成了共识。
“何种情况呢？” proposer 向所有 acceptor 发出一轮请求，如果返回的响应中的大多数的值是相同的，那么 proposer 就认为系统已经达成了共识；并把 该值返回给客户端。Paxos 算法强调的似乎是写，如果去读呢？也需要进行标准的 Paxos 算法过程，最后获得的那个值就是读取到的值。
每个 proposer 之间是平等的，独立的，proposer 之间并不会发生通信。在 Multi Paxos 算法中，为了提高共识算法的效率，会进行选主，这时候 proposer 之间会发生通信。现在我们讨论的是 Basic Paxos，proposer 之间不知道彼此的存在。
我们接下来的推导过程都要戴着单个 proposer 的帽子，看看这个微小的个体是如何参与到这个令人眼花缭乱的协议和过程中去的。
单个 Acceptor 故事在最开始的那个梦中，漫天星光只因我而闪烁 &amp;hellip;
让我们回到故事的起点，那时候我们还没有那么贪婪。只有一个 acceptor，有多个 proposer。这唯一的 acceptor 对于 proposer 提出的值如何决策呢？
等等，proposer 发出的消息格式是什么样子呢？虽然，我们站在第一级台阶上，也要搞清楚一些基本问题。这时候，协议还很简单：
proposer 向唯一的 acceptor 发出了消息，消息中唯一包含的就是提议的值，除此之外没有任何其他东西。
acceptor 收到之后如何反应呢？
Paxos 算法的活性要求我们必须要能够达成对一个值的共识，如今这个重任就放到唯一的 acceptor 身上。acceptor 可以采取两种行动：一是接受（accept), 二是拒绝（reject）。如果接受，接受哪个呢？毕竟 acceptor 对值没有偏好，proposer 之间也是众生平等，不能因为碰巧遇到了某个值就接受了它。换句话 说，对于 acceptor 来说，值本身不能给它提供决策需要的信息。acceptor 只能从其他维度来定义自己的接收规则。
我们需要一个规则，但是又不确定这个规则是什么？路有千万条，该走哪一条，哪一条又是活路呢？此时，我们无妨（不得不）假设我们的算法已经成型，现在要 用它来进行经常测试。先从最简单的场景开始。
如果只有一个 proposer，它只发出了一个提案，也就说整个系统中只有一个提案，那么最终的共识自然是这个提案了。收到提案的 proposer 该如何反应呢？ 拒绝吗？拒绝之后也没有其他提案了，无法达成共识。这个 proposer 只能接收这个唯一的提案。我们的接收规则可能非常复杂，但在当下这种一个proposer， 一个提案和一个acceptor的情况下它必须蕴含能达成的情况。我们观察一下，对于 acceptor 来说，这个唯一的提案有什么特征。前面提到了，acceptor 不会从值本身来决定接收还是拒绝，那么在这里，这个孤单的提案的特征是什么呢？是的，就是“一个”这个特征。一个意味着是第一个也是最后一个。目前，我们 的消息格式十分简陋，只有一个值，到 acceptor 这里的话，由于多个消息的存在，给消息附加了时间信息。
如果 acceptor 按照接收的顺序来决定接收规则呢？ 或者说 acceptor 接收它收到的每个提案。后面这种想法明显不靠谱，如果acceptor如何来者不拒， 系统的共识将会无法收敛。我们还是考虑从顺序上来定义接受规则。在只有一个提案的情况下，acceptor 可以将规则定义为：
a: 接收第一个收到的提案 b: 接收最后一个收到的提案 a 还是 b 呢？如果选 b, “最后一个”是一个相对的概念，意味着接下来没有收到任何消息。而在基于消息的共享模型中，一个消息可能会花费任意长的时间达到， 确定最后一个必须要有一个时间的限制，比如3分钟内。而 Paxos 算法中是没有这样的时间限制的，因此我们只能将规则定义为：
P1 一个Acceptor必须接受它收到的第一个提案 P1听起来有点过于简单，就这？？？别看人家轻描淡写的一句话，在现在这个场景（只有一个 proposer 只发出了一个 提案 给唯一的 acceptor）下是够用的。 当然，我们能隐约感受到它是一个局部的真理。就好像，火鸡养殖场里面，有一只练习时长不满一年的火鸡科学家，它观察到每天下午，它的住处都会出现事物， 于是它推测每天下午都会出现食物，这是一个真理。殊不知，在11月第四个星期三，下午没有出现食物，反而出现一位从未见过的巨人把它抓起来了。因为明天就是 感恩节，它被用来“感恩”了。
人类的记忆容纳不了太多没有逻辑的内容，因为这意味着我们不是踩着台阶上去了，而是从某种无法预测难以理解的地方突然达到了彼岸。我必须介绍一下我们继续 推导的思路，这对急需理解的读者们是一个救赎，不过，首先是自我的救赎。
我们首先假设大厦已经建成，然后有这个幻想去满足一些基本的场景，得到一个基本的简单的局部的规则。这个就是我们思维的起点。之后，我们进行如下的循环：
A: 通过反例发现已有规则的漏洞 B: 提出更加完善的规则 如果幸运的话，我们会在若干个循环后停在B。but, who knows ? 鉴于现在是 2022 年，是 Paxos 算法发表的30多年后，所以我们都心知肚明这是一次 装模作样的推导，我们会成功的，只要是很自然地被我们大脑所接受。
目前我们的 B 是 P1, 接下我们要对他进行挑刺。
多个 Acceptor 一个 acceptor 为啥不行？很简单，如果它挂掉了，proposer 将一直苦等，从它的角度来看，无法达成共识，这就违反了算法的活性要求。一个不行就多个吧。 毕竟，在分布式系统中我们的印象是，多个，有好多个， 服务器不止一个，而是一个集群，给我们提供“高可用”的服务。挂掉一个，不影响服务可用性。
既然是多个 acceptor，我们系统的可用性得到了保证，但是对于共识来说事情变得复杂起来。在只有一个 acceptor 的情况下，proposer 在回复中得到 确认后就认为自己的提案变成了共识。现在有多个acceptor，这些交互的过程又是怎样呢？
如果 proposer 只给一个 acceptor 发送请求，如果幸运的话，这个熟悉的战友挂掉的话，proposer 只能一直等下去了。所以，不仅决策端要配备多个 acceptor，proposer 也要灵活起来，不能把所有的鸡蛋都放在同一个篮子里，它决定给多个 proposer 都发送请求。那么，proposer 到底应该给多少个 acceptor 发送请求才能保证不会出现没人会它的情况呢？
等等，我们的系统不会要求出现所有的 acceptor 都挂掉还能正常进行共识协议工程吗？这可能吗？所以我们在讨论proposer该给多少个 acceptor 发送 消息之前，我们需要对于 acceptor 的集群故障做一个限制：在何种故障程度下共识算法要能够容忍错误并正常工作。
这种故障是指什么呢？Paxos 算法针对的是非拜占庭式的故障模型。对于 acceptor 来说，它可能会运行缓慢，宕机或者重启，但是不可能会破坏或者修改 或者欺骗 proposer，也就说，这里的故障没有“魔法”的存在。何种故障程度值得是集群中有几个可以正常工作（活的的，能产生响应的）。
Paxos 算法的工作的前提是 acceptor 中的多数可用，假设有 5 个 acceptor 节点，之中3个及以上的节点可用就能保证算法正常运行。
我们再回到proposer应该给多少个acceptor发送消息的问题上来。按照人类民主议会制的少数服从多数的选举制度的朴素思想，proposer 至少收到多数 的 acceptor的接受响应后，才可以认为自己的提案已经成为系统的共识。所以最简单的方法是给所有的acceptor都发送消息。
如果共有5个acceptor，其中3个接受了提案，但是中途挂掉了一个，所以只有两个接收的响应。这种情况下，proposer 就不能认为自己的提案被选中。这是一 个反例，也是我们后面要解决的问题。
现在我们需要明确从 proposer 的角度来说，怎样算达成了共识。proposer 在收到的消息中发现有多数接受了自己，就认为共识达成。这是 proposer 端的 决策规则。那么 acceptor 端又该如何定义接受规则呢？
我们先沿用 P1 这个接受规则。P1 实际限制了只能接收第一个收到的提案，意味如果可以接收第二个，那么共识就无法变得难以收敛（当然这是我们的一个直觉， 没有严谨的证明，目前为止，我们还在一系列的猜想当中，完全可以自由行路）。在多个 proposer 同时提案的过程中，acceptor 按照接收的值被划分成多个 不相交的集合。比如在记为 S1 ~ S5 的 acceptor 集群中根据收到的值 v1, v2, v3形成了互补相交的三个集合： {S1, S2}, {S3}, {S4, S5}。 这样就无法形成多数了。
假设为了 v1 让成为多数，proposer1 向 S3 又发出了请求，然后 S3 接受了它。这样我们就无法使用 P1 这个简单的接收规则了。需要修改 acceptor 的 接受规则，怎么改呢？首先排除掉接收每一个收到的提案。接收相同值的提案怎么样？但是在上面的情形中，还是无法形成共识。假如 proposer1, proposer2, proposer 3 都坚持己见，不肯妥协，那么算法是无法达到安全性的。proposer必须要作出让步，毕竟算法的目的是达成共识，进而保证多副本的状态一致，而 不是从单个 proposer 的利益考虑。如果一个 proposer 能够学习到其他 proposer 的提案并进行跟随，那么就有可能形成多数的接受。
proposer 如何学习呢？在正式发出提案之前，先进行一轮查询，询问 acceptor 们是否有已经接受的提案。如果查询过后，没有发现任何接受的提案，它就广播 自己的提案了。这是理想化的情况，假如已有接受的提案了，它应该跟随哪一个提案，以便整个系统快速收敛？到现在为止，提案就是值本身，而不同的值对于 proposer 来说没有什么区别，它需要额外的信息。
acceptor 不能接收每一个收到的提案，如果它接收收到的第一个提案，并接受之后收到的相同值的提案，这样会不会对上面的分裂情形产生帮助呢？并不会。
proposer1, proposer2, proposer 3 失败之后，再进行一轮查询，这时候返回的值有 v1, v2, v3。且不说选择哪一个，就算选择任意一个，继续发出 请求也不会形成多数派，因为 acceptor 那里已经不会修改接受的提案了。在 acceptor 的接受规则这里已经到头了，不能玩出新的花样了。
再次明确一下现在的情况，proposer有3个，分别是proposer-1, proposer-2, proposer-3, acceptor 有5个，分别是S1 ~ S5.
proposer-1 提出的 v1 被 S1, S2 接收； proposer-2 提出的 v2 被 S3 接收； proposer-3 提出的 v3 被 S4, S5 接收。 proposer 的工作过程已经发生了改变，为了学习在失败时追随可能已经成为多数的提案，加速共识的快速收敛，首先要进行一轮查询请求，然后根据情况再发出 一轮提案。目前我们进退两难，分裂的局面难以进行下去，整个系统陷入无效工作的循环当中。
我们能不能避免这种分裂的情况呢？proposer-1,2,3 刚开始查询的返回结果中都显示没有任何已经接收的提案，所以它们随机写入自己的提案。假如我们想让 v1 称为共识，能不能在第一轮查询的时候告知 acceptor 不要接收其他 proposer 的值？这样第二轮的时候肯定能够多数派写入成功。现在 acceptor 不仅 要区分不同的值，还要区分不同的 proposer，那么给每个把每个 proposer 的编号在查询时传递给 acceptor 吧。可是，别忘了，在分布式系统中，每个 proposer 的行为是并发的，假设 proposer-1 给一个多数派集合 Q1 发送了查询请求，这样 Q1 中每个 acceptor 都记住了 proposer-1；同时， proposer-2 给另一个多数派集合 Q2 发送了查询请求，Q2 和 Q1 肯定有交集，交集中至少有一个元素，记作 S_0。这个 S_0 到底是记住 proposer-1， 还是 proposer-2 呢？如果记住收到的第一个查询请求的 proposer，之后这个 proposer 挂掉了，那么这个 acceptor 就废掉了，无法参与投票了；所以， 记住最新的查询请求的 proposer。
第一轮查询时有必要的，首先它是一个学习共识的过程。然后我们对其附加了额外的操作，要求 acceptor 承诺不再接受其他 proposer 的提案。第一轮请求 称为 Prepare 请求。 第二轮请求称为 Accept 请求。这样对于 proposer 来说整个提案过程分为两个阶段（2-Phase）。
如果运气不好，proposer-1 在 Prepare 请求中对他许诺的 acceptor 在中途被更新的 Prepare 请求拐跑了，那么 proposer-1 将会在 Accept 请求 中收到接受到的提案，这时候应该选择哪一个跟随呢？返回的响应中可能包含proposer-1自己发出的提案。
似乎进行不下去了，让我们来看看 Paxos 在 P1 之后的进展吧。
只接受一个值会导致分裂，那么允许接收多个值吧，只是这些值要相同。这和我们的推导似乎有点相似。Paxos 算法给每个提案附加了一个编号，每个 Proposer 发出的提案的编号是严格递增的，且不同的proposer发出的提案编号没有重叠。这引出了 P2.
P2. 如果一个值为 v 的提案被接受了，那么每个更大编号的被接收的提案的值也都是 v. 与我们的推导不同的是，Paxos 给提案附加了编号。这是不太自然很难想到的地方。也许，我们的推导还需要参阅更多的资料，而不是从零开始。
P2 有两个推论:
P2_a. 如果一个值为 v 的提案被接受了，那么被 acceptor 接收的更大编号的提案的值也都是 v. P2_b. 如果一个值伪 v 的提案被接受了，那么由 proposer 发出的更大编号的提案的值也都是 v. 那么 proposer 如何学习到这个已经被接收的提案的值呢？通过 Prepare 请求，这和我们的推导吻合。P2_a 和 P2_b 分别对 acceptor 消费端和 acceptor 生产端都提出了要求。
那么前面分裂的情况解决了吗？并没有。我们仍然需要 acceptor 在 Prepare 请求时给我们一些承诺，Paxos这里导出 P2 的第三个推论：
P2_c. 对于编号为 n，值为 v 的提案被一个多数派 S 接收，则 S 中的acceptor 满足： (a) 没有任何 acceptor 接受过任何编号小于 n 的提案 (b) 在接收过的编号小于 n 的最大编号的提案的值也是 v P2_c 对 acceptor 提出了更为具体化的要求。Prepare 阶段要学习的提案就是编号小于 n 的最大提案的值；那么 acceptor 的承诺是什么，在 Prepare 请求中不接受比 n 小的请求；在 Accept 请求中，不接受编号比 n 小的请求。这就是新的规则：
P1_a. 一个acceptor接收编号为 n 的提案当且仅当它没有响应过任何编号大于n的prepare请求。 这里的响应其实就是许诺，不响应就是不许诺。</content></entry><entry><title>Paxos Simple 阅读笔记</title><url>/post/seventh/</url><categories/><tags/><content type="html">问题定义 什么是共识算法（Consensus Algorithm）：
一个集合中的每个进程都能对某个变量的值作出提案。共识算法保证在提案（proposed）的值中只有一个被选中（chosen）。如果没有值被提出，那么就没有 值被选中。如果已经有值被选中了，那么进程能够学习（learn）到这个选中的值。
共识算法的活性要求（safety requirements）：
在提案的值中只有一个能被选中 仅选择一个值 一个进程只有在值被选中后才能知道这个被选中的值 活性要求保证了某个被提案的值最终会被选中，如果一个值别选中之后，一个进程最终能够学习到这个值。
Paxos 算法中包含三类角色，分别是：
proposers, 提案者：负责对变量的值进行提案 acceptors，接受者：负责对提案进行决策 —— 接受或者拒绝 learners，学习者：在值被选中之后，进行学习 在具体实现中，一个进程可能扮演多种角色。
假设进程之间可以通过消息进行通信。Paxos 使用常见的，异步的，非拜占庭（non-Byzantine）模型：
进程以任意速度运行，可能会因为由于崩溃而失败，可能重启。因为，进程完全有可能在一个值被选中后失败，然后重启，所以必须借助持久化存储来保存 一些决策信息。 消息会花费任意上的时间，可能会重复，可能会丢失，但是绝不可能被破坏。 如何选择一个值 单个 Acceptor 最简单的方法是只有一个acceptor。一个 proposer 发送一个提案（proposal）给 acceptor，acceptor 接受（accepted）第一个收到的提案。
只有一个 Acceptor，最显而易见的问题是：如果它挂掉了，那么共识就无法进行下去。
多个 Acceptor 很自然的，我们想到使用多个 Acceptor 来选择一个值。既然有多个 Acceptor，那么 Proposer 将提案发送给多个 Acceptor。只有当足够多 的Acceptor接受了某个值，那么它才算被选中了。这是多个 Acceptor 下的选择策略。那多少才足够呢？超过半数。1/3 行不行呢？如果有 1/3 的 Acceptor 选中了某个值，另外 2/3 选中了另外一个值，这样就选中两个值，不满足算法的活性要求。那么 1/2 行不行呢？也是同样的问题。如果超过半数，根据鸽笼原理， 不可能有两个大小超过半数而没有交集的集合选中不同的值。
假设我们共有 5 个Acceptor，分别为 S1, S2, S3, S4, S5. 其中：
S1, S2, S3 选中了值 v1 S2, S4, S5 选中了值 v2 集合 {S1, S2, S3} 和 {S2, S4, S5} 之间存在交集 {S2}。如果要达成共识，即 v1 = v2 的话，S2 只能选择一个值。
因为 S1, S3 和 S2 选择相同， S4, S5 和 S2 选择相同，所以 Acceptor 之间达成了共识。
假如没有失败和消息丢失，在一个 Proposer 的情况下，并且该 Proposer 只提出了一个提案，那么这个提案应该被接受并选中。这意味着满足下面的要求：
P1. 一个 Acceptor 必须接受它收到的第一个提案 但是这个要求会导致一个问题。假设几个proposer各自提案了不同的值，导致每个acceptor都接受了一个值，但是没有一个值被大多数acceptor所接受。
P1 和 一个值被选中当且仅当被多数acceptor接受要求 acceptor 必须能够接受多个提案。这个结论看着很简单，却不是那么自然地容易得出。为什么 acceptor 只接受一个提案就不能形成共识呢？前面提到，形成共识的前提是两个多数的交集接受了同一个值。
假设我们共有 5 个Acceptor，分别为 S1, S2, S3, S4, S5. 其中：
S1, S2, S3 选中了值 v1 S2, S4, S5 选中了值 v2 加入 S2 先接受了 v1, 那么 S1, S2, S3 接受了 v1, S4 和 S5 接受了 v2，v1 被多数接受，这不是形成了共识了吗？但如果 S2 挂掉，剩下的 S1, S3 与 S4, S5 分别接收了 v1 和 v2, 此时又形成了分裂。这种情况下不能形成共识。
我们已经通过例子证明了接受单个提案容易导致单点故障，那么不妨让acceptor能够接收多个提案。
“多个提案”，acceptor 如何知道收到的两条消息是不同的提案呢？我们给提案附加一个编号，这样的话提案就由两个部分组成：
提案编号 提案的值 为了避免混淆，我们要求不同的提案必须有不同的编号。这里的不同是指不同的消息。提案的内涵得到了扩容，值被选中的条件也需要稍作调整。
一个值被选中当且仅当一个拥有该值的提案被大多数acceptor所接受。
在这种情况下，我们说提案（包含它的值）被选中。
我们允许多个提案被选中，但是保证所有被选中的提案都有相同的值。编号肯定有大小，现在保证对于某个proposer而言，后发出的提案的编号更大。 如果多个提案被选中，那么后面的提案编号更大，但是值确实和被选中的值相同。即满足：
P2. 如果一个值为 v 的提案被选中，那么每个更高编号的被选中的提案的值也是 v 为什么要限制“更大的编号”呢？“如果一个值为 v 的提案被选中，那么后面被选中的提案的值也是 v”，这样说行不行呢？这是一个疑问。
为了被选中，一个提案至少要被一个acceptor所接受。所以，为了满足 P2，我们必须满足：
P2^a 如果一个值为v的提案被选中之后，那么更大编号的由acceptor接收的提案的值也为 v. 有了 P2^a，我们仍然要满足 P1。假设一个提案被一个从未接受过任何提案的acceptor c 所接受。这时候一个新的 proposer 醒来了，发出了一个更大的 但是不同值的提案。P1 要求 c 接受这个提案，此时已经有多数接受了某个值，即已经有值被选中了，这样就违反了 P2^a。
为了同时满足 P1 和 P2^a，要求我们加强 P2^a 到 P2^b
P2^b 如果一个值为v的值已经被选中，那么任何更大的编号由proposer发出的提案的值都是v 因为一个提案是先由 proposer 发出，然后由 acceptor 接收，所以由 P2^b 可以满足 P2^a，间接满足 P2.
为了发现如何满足 P2^b，让我们考虑如何证明它成立。
假设已经有编号为 m, 值为 v 的提案被选中，那么需要证明任何编号大于 m 的编号 n 的提案的值也是 v.
我们可以在 n 上面使用数据归纳法从而简化证明。我们可以证明在假设编号在 m..(n-1) 之间的提案都有值 v 的前提下证明满足 P2^b.
当编号为 m 的编号的提案被选中时，肯定有一个包含多数的集合 C，其中的 acceptor 都接受了它。将这个情况与归纳假设结合起来，m 被选中意味着：
Every acceptor in C has accpeted a proposal with number in m..(n-1), and every proposal with number in m..(n-1) accepted by any acceptor has value v.
因为任意多数的集合 S 至少包含 C 的一个元素，我们通过维护下面的不变性来保证编号为 n 的 提案也有值 v:
P2^c 对于任意 v 和 n, 如果编号为 n, 值为 v 的提案发出后， 存在一个多数 acceptor 的集合 S 满足下面两个条件： (a) S 中没有 acceptor 接受过编号小于 n 的提案 或者 (b) v 是 S 中acceptor所接收到的编号小于 n 的最大编号的提案的值。 我们因此可以维护 P2^c 进而来满足 P2^b.
为了维护 P2^c，一个 proposer 如果想发出一个编号为 n 的提案，必须学习到编号小于 n 的最大编号的提案（如果有的话），这个提案已经或者将要被某些 多数集合的 acceptor 所接受。
proposer 要求 acceptor 不在接受任意编号小于 n 的提案。这样就形成了下面的发出提案的算法：
一个 proposer 选择一个新的提案编号 n，并向acceptor的某个集合发出请求，要求它们响应： (a) 许诺不再接受任何编号小于 n 的提案
(b) 如果有的话，返回acceptor所接受的最大的编号小于n的提案
这样的请求叫做一个 prepare 请求。
如果 proposer 收到多数 acceptor 的应答，那么它可以发出一个编号为 n, 值为 v 的提案；其中 v 是它收到的所有响应中最大编号的提案的值，或者 它自己提议的值，如果没有收到任何响应的话。 一个 proposer 发出一个提案请求 acceptor 接收它的提案。这个请求叫做 accept 请求。
上面两步描述了 proposer 的算法。acceptor 的算法是怎样的呢？</content></entry><entry><title>Paxos 算法资料整理</title><url>/post/fifth/</url><categories/><tags/><content type="html">Basic Paxos Paxos Made Simple - Leslie Lamport
可靠分布式系统-paxos的直观解释
可靠分布式系统-paxos的直观解释.pdf
Paxos made simple 论文导读
知行学社——paxos和分布式系统
Understanding Paxos
Multi Paxos Implementing Replicated Logs with Paxos - Diego Ongaro
Paxos lecture (Raft user study)
用paxos实现多副本日志系统&amp;ndash;basic paxos部分
用paxos实现多副本日志系统&amp;ndash;multi paxos部分</content></entry><entry><title>一些Windows下小工具推荐</title><url>/post/third/</url><categories/><tags/><content type="html">第三篇，我想来聊一下windows10环境下的好用的小工具。
Listary：文件搜索工具。速度非常快，搜索匹配度高。最近更新到 6.x 版本，界面升级了。双击 Ctrl 唤起。 uTools：应用启动工具。Alt + 空格键 唤起。再也不需要自己去桌面上找图标然后双击了。 WizTree：磁盘分析工具。分析非常快，以百分比的形式显示哪些文件夹和文件占用磁盘比例最大，让我们释放磁盘空间时有的放矢。 Sublime Text：文本编辑器。功能不是很强大，但是打开非常快。打字交互做得很好，适合作为普通文本编辑器。默认主题也很好看。 Bandzip：非常好用的解压缩软件。 KeePass：密码管理软件。可以用来管理一些不太重要的密码。</content></entry><entry><title>Java 开发者的磁盘管理经验</title><url>/post/second/</url><categories/><tags/><content type="html">Hugo 有时候会有点问题，看不见 post.
今天我想来聊聊 Java 开发者的一些电脑存储管理的经验。
第一呢，是IDEA的 idea.properties 文件中的几个路径，比如插件存放的路径，索引的路径。这些都可以修改。如果使用默认配置的话，时间长了，C 盘很容易被占满。
第二个呢，是关于 Maven 的本地仓库。也不要放在 C 盘。IDEA 每次打开新的工程师会使用自己默认的 Maven 配置，我们可以新建一个打开项目的模板，在里面配置自己的Maven仓库位置和配置。
第三个，关于 JDK 版本的管理。我们可能会用到多个 JDK，从 1.6, 1.8, 11 到 17 等。可以用一个专门的文件夹来存放JDK。</content></entry><entry><title>About</title><url>/about/</url><categories/><tags/><content type="html">关于</content></entry></search>